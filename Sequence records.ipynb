{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Record\n",
    "\n",
    "Essentially a sequence with database metadata attached to it. Depending on the source, this metadata can be surprisingly rich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: YP_025292.1\n",
      "Name: HokC\n",
      "Description: toxic membrane protein, small\n",
      "Number of features: 0\n",
      "Seq('MKQHKAMIVALIVICITAVVAALVTRKD', IUPACProtein())\n"
     ]
    }
   ],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import IUPAC\n",
    "record =SeqRecord(Seq(\"MKQHKAMIVALIVICITAVVAALVTRKD\",\n",
    " IUPAC.protein),\n",
    " id=\"YP_025292.1\", name=\"HokC\",\n",
    " description=\"toxic membrane protein, small\")\n",
    "print record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You get a `SeqRecord` when you:\n",
    "- parse a file with sequence data in one of the standard formats\n",
    "- obtain sequence data from an online resource (eg NCBI, UniProt, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrez Utilities - Sequence queries\n",
    "\n",
    "Online access to NCBI's data. The [Bio.Entrez](http://biopython.org/DIST/docs/api/Bio.Entrez-module.html) module makes use of the Entrez\n",
    "Programming Utilities (also known as EUtils), described in detail [here at NCBI](http://www.ncbi.nlm.nih.gov/entrez/utils/). You usually get an XML output, which is parsed using some utility function in `Bio.Entrez`.\n",
    "\n",
    "**Important:** Be aware that the Entrez utilities impose usage limits and you can get yourself blacklisted if you violate those. BioPython takes care of keeping an eye on those for you. You also should fill in a non-fake email address. See the [Frequency section](http://www.ncbi.nlm.nih.gov/books/NBK25497/#chapter2\\2e Frequency_Timing_and_Registrati) in the manual.\n",
    "\n",
    "# esearch\n",
    "\n",
    "`esearch` searches and retrieves primary IDs (for use in EFetch, ELink, and ESummary) and term translations and optionally retains results for future use in the user's environment. `efetch` can then be used to download the actual records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handle: <addinfourl at 31691048 whose fp = <socket._fileobject object at 0x1e35450>>\n",
      "\n",
      "\n",
      "Content: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<!DOCTYPE eSearchResult PUBLIC \"-//NLM//DTD esearch 20060628//EN\" \"http://eutils.ncbi.nlm.nih.gov/eutils/dtd/20060628/esearch.dtd\">\n",
      "<eSearchResult><Count>3</Count><RetMax>3</RetMax><RetStart>0</RetStart><IdList>\n",
      "<Id>377580661</Id>\n",
      "<Id>156535673</Id>\n",
      "<Id>156535671</Id>\n",
      "</IdList><TranslationSet><Translation>     <From>opuntia[ORGN]</From>     <To>\"Opuntia\"[Organism]</To>    </Translation></TranslationSet><TranslationStack>   <TermSet>    <Term>\"Opuntia\"[Organism]</Term>    <Field>Organism</Field>    <Count>1725</Count>    <Explode>Y</Explode>   </TermSet>   <TermSet>    <Term>accD[All Fields]</Term>    <Field>All Fields</Field>    <Count>161156</Count>    <Explode>N</Explode>   </TermSet>   <OP>AND</OP>  </TranslationStack><QueryTranslation>\"Opuntia\"[Organism] AND accD[All Fields]</QueryTranslation></eSearchResult>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "Entrez.email = \"my_little_self@utu.fi\"\n",
    "handle = Entrez.esearch(db=\"nucleotide\", retmax=10, term=\"opuntia[ORGN] accD\")\n",
    "print \"Handle:\", handle #A file-like object, you can read it\n",
    "content=handle.read()\n",
    "print \"\\n\\nContent:\", content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's XML allright. Let's parse it. The primary method to do this is `Entrez.read()` but it expects a file. We have already consumed our handle - we read the data from it to the end so that it cannot be used again. We could query again, or we can use `StringIO` which is a module which can simulate file objects on top of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import StringIO #Useful whenever you have your data in a string but a function which expects a file\n",
    "content_filelike=StringIO.StringIO(content)\n",
    "equery_result=Entrez.read(content_filelike)\n",
    "print \"Parsed result of equery:\", equery_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are having a dictionary. Most important here is the `IdList` key which holds the IDs which fit our query. Now we can fetch those.\n",
    "\n",
    "### read() vs. parse()\n",
    "\n",
    "Throughout BioPython in the different modules the function `read()` is used to parse an output which only has a single record (of whatever kind) and it returns that record plus it may even throw an error if the output seems to contain more than one record. On the other hand `parse()` is used to parse an output which has several records and returns a generator over them (ie something you can for-loop over once, or turn into a list with `list()`).\n",
    "\n",
    "## efetch\n",
    "\n",
    "Now that we have our IDs, we can fetch the records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "handle=Entrez.efetch(\"nucleotide\",id=equery_result['IdList'],retmode=\"xml\")\n",
    "efetch_result=Entrez.parse(handle)\n",
    "print \"Efetch result\", efetch_result #This gives a \"generator\". You may want to make this into a list, or loop over it\n",
    "for r in efetch_result:\n",
    "    print r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is **not** what we wanted! What we want is a `SeqRecord` object. Reason: `Entrez.parse()` is a generic function for parsing Entrez XML. We are receiving nucleotide database records, ie sequences. For this, we want [Bio.SeqIO](http://biopython.org/DIST/docs/_api_159/Bio.SeqIO-module.html) which is specialized in parsing the various sequence formats we can meet and in this particular case the *GenBank* format (`gb`  is what we want)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Bio.SeqIO as SeqIO\n",
    "handle=Entrez.efetch(\"nucleotide\",id=equery_result['IdList'],rettype=\"gb\") #Note: this now says \"gb\" to get the right format\n",
    "efetch_result=SeqIO.parse(handle,\"gb\") #Note: this used to read Entrez.parse(handle)\n",
    "print \"Efetch result\", efetch_result #This gives a \"generator\". You may want to make this into a list, or loop over it\n",
    "for r in efetch_result:\n",
    "    print repr(r)\n",
    "    print\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better. Now we have SeqRecords. Let us summarize everything into a nice piece of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "Entrez.email = \"my_little_self@utu.fi\"\n",
    "\n",
    "def fetch_records(query):\n",
    "    search_result_handle=Entrez.esearch(db=\"nucleotide\", retmax=10, term=query) #Query Entrez\n",
    "    search_result=Entrez.read(search_result_handle) #Parse the XML data you get in reply\n",
    "    efetch_result_handle=Entrez.efetch(db=\"nucleotide\", id=search_result['IdList'],rettype=\"gb\") #Now fetch the actual sequences in GenBank format\n",
    "    seq_records=SeqIO.parse(efetch_result_handle,format=\"gb\") #Now parse the obtained data using SeqIO\n",
    "    return seq_records\n",
    "\n",
    "for seq_rec in fetch_records(\"opuntia[ORGN] accD\"):\n",
    "    print repr(seq_rec)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search & download recap (1)\n",
    "\n",
    "- `Entrez.esearch()` to get a reply with list of IDs\n",
    "- `Entrez.efetch()` to grab the actual records\n",
    "- `SeqIO.parse()` to obtain a sequence of SeqRecord objects\n",
    "\n",
    "This is okay for simple small queries but is highly discouraged for large queries. NCBI expects you to use the *query history* functionality which lets them bind your fetch to a previous search and use their internal caching mechanisms. Turn it on with `usehistory=\"y\"` like such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "Entrez.email = \"my_little_self@utu.fi\"\n",
    "\n",
    "search_result_handle=Entrez.esearch(db=\"nucleotide\", retmax=10, term=\"opuntia[ORGN] accD\", usehistory=\"y\") #Query Entrez with history on\n",
    "search_result=Entrez.read(search_result_handle) #Parse the XML data you get in reply\n",
    "print \"Search_result:\", search_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `QueryKey` and `WebEnv` keys. This is the information which identifies your result set at NCBI's server and can be used to fetch the records like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "efetch_result_handle=Entrez.efetch(db=\"nucleotide\",\n",
    "                                   query_key=search_result[\"QueryKey\"],\n",
    "                                   webenv=search_result[\"WebEnv\"],\n",
    "                                   rettype=\"gb\") #Now fetch the actual sequences in GenBank format. Note how I don't give the IDs!\n",
    "seq_records=SeqIO.parse(efetch_result_handle,format=\"gb\") #Now parse the obtained data using SeqIO\n",
    "for r in seq_records:\n",
    "    print repr(r)\n",
    "    print\n",
    "    print\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search & download recap (2)\n",
    "\n",
    "- `Entrez.esearch(..., usehistory=\"y\")` to get a reply and webenv + query_key\n",
    "- `Entrez.efetch(..., webenv=, query_key=)` to grab the actual records from the previous search\n",
    "- `SeqIO.parse()` to obtain a sequence of SeqRecord objects\n",
    "\n",
    "Great! Now our problem is that if we have a large result set, thousands of IDs, Entrez doesn't let us grab them all at once with a single efetch. We need to get them bit-by-bit. Here's a complete example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "Entrez.email = \"my_little_self@utu.fi\"\n",
    "\n",
    "def fetch_records(query, ret_max=10, fetch_batch=5):\n",
    "    search_result_handle=Entrez.esearch(db=\"nucleotide\", retmax=ret_max, term=query, usehistory=\"y\") #Query Entrez\n",
    "    search_result=Entrez.read(search_result_handle) #Parse the XML data I get in reply\n",
    "    #The only thing you care about is Count, and the Webenv+QueryKey data\n",
    "    all_records=[] #This will be our result list\n",
    "    #Divide into blocks of fetch_batch results, download one at a time\n",
    "    for start_index in range(0,len(search_result[\"IdList\"]),fetch_batch):\n",
    "        efetch_result_handle=Entrez.efetch(db=\"nucleotide\", \n",
    "                                           retstart=start_index,\n",
    "                                           retmax=fetch_batch,\n",
    "                                           webenv=search_result[\"WebEnv\"],\n",
    "                                           query_key=search_result[\"QueryKey\"],\n",
    "                                           rettype=\"gb\") #Now fetch the actual sequences in GenBank format\n",
    "        #add these records into our list\n",
    "        all_records.extend(SeqIO.parse(efetch_result_handle,format=\"gb\")) #Now parse the obtained data using SeqIO\n",
    "    return all_records\n",
    "\n",
    "fetched_records_p53=fetch_records(\"p53\", ret_max=50, fetch_batch=10) #get max 50 records, fetch 10 at a time\n",
    "print \"Fetched\", len(fetched_records_p53), \"records\"\n",
    "print \"First few:\", fetched_records_p53[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search & download - final version\n",
    "\n",
    "- `Entrez.esearch(..., retmax=, usehistory=\"y\")` to get a reply and webenv + query_key, searches for retmax records\n",
    "- `for batch_idx in range(0, total_num_of_results, download_batch)` to chop the results into download_batch sized chunks\n",
    "- `Entrez.efetch(retstart=, retmax=download_batch, webenv=, query_key=)` to grab one batch at a time\n",
    "- `SeqIO.parse()` to obtain a sequence of SeqRecord objects for every batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab a protein and see what the record has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tp53_rec=SeqIO.read(Entrez.efetch(db=\"protein\",id=[\"NP_000537\"],rettype=\"gb\"),\"gb\")\n",
    "print repr(tp53_rec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `seq` sequence itself, Seq object\n",
    "- `id` ID used to identify the sequence, accession number, string\n",
    "- `name` name for the sequence, string\n",
    "- `description` readable description or expressive name for the sequence, string\n",
    "- `letter_annotations` dictionary of additional information about the letters in the sequence\n",
    "- `annotations` dictionary of additional information about the sequence\n",
    "- `features` A list of [SeqFeature](http://biopython.org/DIST/docs/api/Bio.SeqFeature.SeqFeature-class.html) objects with information about the features on a sequence\n",
    "- `dbxrefs` A list of database cross-references as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir(tp53_rec)\n",
    "help(tp53_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in tp53_rec.__dict__:\n",
    "    if not key.startswith('_'):\n",
    "        print key, str(tp53_rec.__getattribute__(key))[:50]+\"...\"\n",
    "for key,val in tp53_rec.annotations.iteritems():\n",
    "    print key, \" \"*15, str(val)[:50]+\"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the information you get depends on the format. Let's try with fasta to see that we get next to nothing, compared to the genbank format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print Entrez.efetch(db=\"protein\",id=[\"NP_000537\"],rettype=\"fasta\").read()\n",
    "tp53_rec_fasta=SeqIO.read(Entrez.efetch(db=\"protein\",id=[\"NP_000537\"],rettype=\"fasta\"),\"fasta\")\n",
    "for key in tp53_rec_fasta.__dict__:\n",
    "    if not key.startswith('_'):\n",
    "        print key, str(tp53_rec_fasta.__getattribute__(key))[:50]+\"...\"\n",
    "for key,val in tp53_rec_fasta.annotations.iteritems():\n",
    "    print key, \" \"*15, str(val)[:50]+\"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "Annotated features along the sequence. Best seen in the [source](http://www.ncbi.nlm.nih.gov/nuccore/NM_001276697.1). The complete list of possible feature types is [here](http://www.ncbi.nlm.nih.gov/Sitemap/samplerecord.html#FeaturesB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in tp53_rec.features:\n",
    "    print f.type, f.location, f.qualifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#extract all CDS from a gene\n",
    "tp53_rec_gene=SeqIO.read(Entrez.efetch(db=\"nucleotide\",id=[\"NM_001276697.1\"],rettype=\"gb\"),\"gb\")\n",
    "for f in tp53_rec_gene.features:\n",
    "    if f.type==\"CDS\":\n",
    "        print \"CDS at\", f.location\n",
    "        extracted=f.extract(tp53_rec_gene)\n",
    "        print repr(extracted)\n",
    "        print extracted.seq\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File I/O\n",
    "\n",
    "`SeqIO.read()` and `.parse()` also work with file name or an open file. And `SeqIO.write(sequences,filename,format)` can write into a file in a [number of formats](http://biopython.org/wiki/SeqIO#File_Formats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"records written:\", SeqIO.write([tp53_rec_gene],\"tp53.gb\",\"gb\")\n",
    "tp53_rec_gene_fromfile=SeqIO.read(\"tp53.gb\",\"gb\")\n",
    "print repr(tp53_rec_gene_fromfile)\n",
    "print tp53_rec_gene_fromfile==tp53_rec_gene #Why false?\n",
    "print tp53_rec_gene_fromfile.seq==tp53_rec_gene.seq #Why true?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
