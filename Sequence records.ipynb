{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Record\n",
    "\n",
    "Essentially a sequence with database metadata attached to it. Depending on the source, this metadata can be surprisingly rich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import IUPAC\n",
    "record =SeqRecord(Seq(\"MKQHKAMIVALIVICITAVVAALVTRKD\",\n",
    " IUPAC.protein),\n",
    " id=\"YP_025292.1\", name=\"HokC\",\n",
    " description=\"toxic membrane protein, small\")\n",
    "print record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You get a `SeqRecord` when you:\n",
    "- parse a file with sequence data in one of the standard formats\n",
    "- obtain sequence data from an online resource (eg NCBI, UniProt, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrez Utilities - Sequence queries\n",
    "\n",
    "Online access to NCBI's data. The [Bio.Entrez](http://biopython.org/DIST/docs/api/Bio.Entrez-module.html) module makes use of the Entrez\n",
    "Programming Utilities (also known as EUtils), described in detail [here at NCBI](http://www.ncbi.nlm.nih.gov/entrez/utils/). You usually get an XML output, which is parsed using some utility function in `Bio.Entrez`.\n",
    "\n",
    "**Important:** Be aware that the Entrez utilities impose usage limits and you can get yourself blacklisted if you violate those. BioPython takes care of keeping an eye on those for you. You also should fill in a non-fake email address.\n",
    "\n",
    "# esearch\n",
    "\n",
    "esearch searches and retrieves primary IDs (for use in EFetch, ELink, and ESummary) and term translations and optionally retains results for future use in the user's environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "Entrez.email = \"my_little_self@utu.fi\"\n",
    "handle = Entrez.esearch(db=\"nucleotide\", retmax=10, term=\"opuntia[ORGN] accD\")\n",
    "print \"Handle:\", handle #A file-like object, you can read it\n",
    "content=handle.read()\n",
    "print \"\\n\\nContent:\", content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's XML allright. Let's parse it. The primary method to do this is `Entrez.read()` but it expects a file. We have already consumed our handle, so it cannot be used again. We could query again, or we can use `StringIO` which is a module which can simulate file objects on top of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import StringIO\n",
    "content_filelike=StringIO.StringIO(content)\n",
    "equery_result=Entrez.read(content_filelike)\n",
    "print \"Parsed result of equery:\", equery_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are having a dictionary. Most important here is the `IdList` key which holds the IDs which fit our query. Now we can fetch those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "handle=Entrez.efetch(\"nucleotide\",id=equery_result['IdList'],retmode=\"xml\")\n",
    "efetch_result=Entrez.parse(handle)\n",
    "print \"Efetch result\", efetch_result #This gives a \"generator\". You may want to make this into a list, or loop over it\n",
    "for r in efetch_result:\n",
    "    print r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is **not** what we wanted! What we want is a `SeqRecord` object. Reason: `Entrez.parse()` is a generic function for parsing Entrez XML. We are receiving nucleotide database records, ie sequences. For this, we want [Bio.SeqIO](http://biopython.org/DIST/docs/_api_159/Bio.SeqIO-module.html) which is specialized in parsing the various sequence formats we can meet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Bio.SeqIO as SeqIO\n",
    "handle=Entrez.efetch(\"nucleotide\",id=equery_result['IdList'],rettype=\"gb\")\n",
    "efetch_result=SeqIO.parse(handle,\"gb\") #Note: this used to read Entrez.parse(handle)\n",
    "print \"Efetch result\", efetch_result #This gives a \"generator\". You may want to make this into a list, or loop over it\n",
    "for r in efetch_result:\n",
    "    print repr(r)\n",
    "    print\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better. Now we have SeqRecords. Let us summarize everything into a nice piece of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "Entrez.email = \"my_little_self@utu.fi\"\n",
    "\n",
    "def fetch_records(query):\n",
    "    search_result_handle=Entrez.esearch(db=\"nucleotide\", retmax=10, term=query) #Query Entrez\n",
    "    search_result=Entrez.read(search_result_handle) #Parse the XML data you get in reply\n",
    "    efetch_result_handle=Entrez.efetch(db=\"nucleotide\", id=search_result['IdList'],rettype=\"gb\") #Now fetch the actual sequences in GenBank format\n",
    "    seq_records=SeqIO.parse(efetch_result_handle,format=\"gb\") #Now parse the obtained data using SeqIO\n",
    "    return seq_records\n",
    "\n",
    "for seq_rec in fetch_records(\"opuntia[ORGN] accD\"):\n",
    "    print repr(seq_rec)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search & download recap (1)\n",
    "\n",
    "- `Entrez.esearch()` to get a reply with list of IDs\n",
    "- `Entrez.efetch()` to grab the actual records\n",
    "- `SeqIO.parse()` to obtain a sequence of SeqRecord objects\n",
    "\n",
    "This is okay for simple small queries but is highly discouraged for large queries. NCBI expects you to use the *query history* functionality which lets them bind your fetch to a previous search and use their internal caching mechanisms. Turn it on with `usehistory=\"y\"` like such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "Entrez.email = \"my_little_self@utu.fi\"\n",
    "\n",
    "search_result_handle=Entrez.esearch(db=\"nucleotide\", retmax=10, term=\"opuntia[ORGN] accD\", usehistory=\"y\") #Query Entrez with history on\n",
    "search_result=Entrez.read(search_result_handle) #Parse the XML data you get in reply\n",
    "print \"Search_result:\", search_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `QueryKey` and `WebEnv` keys. This is the information which identifies your result set at NCBI's server and can be used to fetch the records like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "efetch_result_handle=Entrez.efetch(db=\"nucleotide\",\n",
    "                                   query_key=search_result[\"QueryKey\"],\n",
    "                                   webenv=search_result[\"WebEnv\"],\n",
    "                                   rettype=\"gb\") #Now fetch the actual sequences in GenBank format. Note how I don't give the IDs!\n",
    "seq_records=SeqIO.parse(efetch_result_handle,format=\"gb\") #Now parse the obtained data using SeqIO\n",
    "for r in seq_records:\n",
    "    print repr(r)\n",
    "    print\n",
    "    print\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search & download recap (2)\n",
    "\n",
    "- `Entrez.esearch(..., usehistory=\"y\")` to get a reply and webenv + query_key\n",
    "- `Entrez.efetch(..., webenv=, query_key=)` to grab the actual records from the previous search\n",
    "- `SeqIO.parse()` to obtain a sequence of SeqRecord objects\n",
    "\n",
    "Great! Now our problem is that if we have a large result set, thousands of IDs, Entrez doesn't let us grab them all at once with a single efetch. We need to get them bit-by-bit. Here's a complete example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "Entrez.email = \"my_little_self@utu.fi\"\n",
    "\n",
    "def fetch_records(query, ret_max=10, fetch_batch=5):\n",
    "    search_result_handle=Entrez.esearch(db=\"nucleotide\", retmax=ret_max, term=query, usehistory=\"y\") #Query Entrez\n",
    "    search_result=Entrez.read(search_result_handle) #Parse the XML data I get in reply\n",
    "    #The only thing you care about is Count, and the Webenv+QueryKey data\n",
    "    all_records=[] #This will be our result list\n",
    "    #Divide into blocks of fetch_batch results, download one at a time\n",
    "    for start_index in range(0,len(search_result[\"IdList\"]),fetch_batch):\n",
    "        efetch_result_handle=Entrez.efetch(db=\"nucleotide\", \n",
    "                                           retstart=start_index,\n",
    "                                           retmax=fetch_batch,\n",
    "                                           webenv=search_result[\"WebEnv\"],\n",
    "                                           query_key=search_result[\"QueryKey\"],\n",
    "                                           rettype=\"gb\") #Now fetch the actual sequences in GenBank format\n",
    "        #add these records into our list\n",
    "        all_records.extend(SeqIO.parse(efetch_result_handle,format=\"gb\")) #Now parse the obtained data using SeqIO\n",
    "    return all_records\n",
    "\n",
    "fetched_records_p53=fetch_records(\"p53\", ret_max=50, fetch_batch=10) #get max 50 records, fetch 10 at a time\n",
    "print \"Fetched\", len(fetched_records_p53), \"records\"\n",
    "print \"First few:\", fetched_records_p53[:5]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
